16/10/25 11:34:59 INFO CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]
16/10/25 11:35:00 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, type=DEFAULT, always=false, sampleName=Ops)
16/10/25 11:35:00 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, type=DEFAULT, always=false, sampleName=Ops)
16/10/25 11:35:00 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, type=DEFAULT, always=false, sampleName=Ops)
16/10/25 11:35:00 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
16/10/25 11:35:00 DEBUG Groups:  Creating new Groups object
16/10/25 11:35:00 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
16/10/25 11:35:00 DEBUG NativeCodeLoader: Loaded the native-hadoop library
16/10/25 11:35:00 DEBUG JniBasedUnixGroupsMapping: Using JniBasedUnixGroupsMapping for Group resolution
16/10/25 11:35:00 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
16/10/25 11:35:00 DEBUG Shell: setsid exited with exit code 0
16/10/25 11:35:00 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
16/10/25 11:35:00 DEBUG SparkHadoopUtil: running as user: platuser
16/10/25 11:35:00 DEBUG UserGroupInformation: hadoop login
16/10/25 11:35:00 DEBUG UserGroupInformation: hadoop login commit
16/10/25 11:35:00 DEBUG UserGroupInformation: using kerberos user:platuser/10.2.177.208@OTOCYON.COM
16/10/25 11:35:00 DEBUG UserGroupInformation: UGI loginUser:platuser/10.2.177.208@OTOCYON.COM (auth:KERBEROS)
16/10/25 11:35:00 DEBUG UserGroupInformation: PrivilegedAction as:platuser (auth:SIMPLE) from:org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:74)
16/10/25 11:35:00 INFO SecurityManager: Changing view acls to: platuser
16/10/25 11:35:00 INFO SecurityManager: Changing modify acls to: platuser
16/10/25 11:35:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(platuser); users with modify permissions: Set(platuser)
16/10/25 11:35:00 DEBUG UserGroupInformation: Found tgt Ticket (hex) =
0000: 61 82 01 63 30 82 01 5F   A0 03 02 01 05 A1 0D 1B  a..c0.._........
0010: 0B 4F 54 4F 43 59 4F 4E   2E 43 4F 4D A2 20 30 1E  .OTOCYON.COM. 0.
0020: A0 03 02 01 02 A1 17 30   15 1B 06 6B 72 62 74 67  .......0...krbtg
0030: 74 1B 0B 4F 54 4F 43 59   4F 4E 2E 43 4F 4D A3 82  t..OTOCYON.COM..
0040: 01 25 30 82 01 21 A0 03   02 01 12 A1 03 02 01 01  .%0..!..........
0050: A2 82 01 13 04 82 01 0F   79 D1 21 7D 6E 71 57 A8  ........y.!.nqW.
0060: CF 3D CB 7C 21 E4 F8 C3   18 20 76 81 BF F9 4F 3C  .=..!.... v...O<
0070: 35 9F DD 5C 86 F5 60 06   B1 50 1F BA 6C 3F 23 A2  5..\..`..P..l?#.
0080: 92 98 60 3F 08 F4 13 63   8B 50 E8 B6 19 25 98 A5  ..`?...c.P...%..
0090: 38 A3 DA 54 70 66 C6 AF   F5 4E 49 DB B5 DD 78 6B  8..Tpf...NI...xk
00A0: 2A D9 EE 0E 58 F6 EF 12   DF F2 54 A6 90 C1 10 D5  *...X.....T.....
00B0: 63 1D 79 51 FF DA 00 76   F9 82 15 80 52 64 D8 59  c.yQ...v....Rd.Y
00C0: 2F 38 35 A0 03 CC 36 FA   90 56 73 0F A0 8B CA 10  /85...6..Vs.....
00D0: 4B F2 24 29 A9 62 B7 11   8A BD C9 D1 C7 FE 58 C4  K.$).b........X.
00E0: 82 0B E1 59 77 AE D0 20   6C 14 2A F2 26 C1 70 B2  ...Yw.. l.*.&.p.
00F0: C7 47 76 49 7E 02 9A 2E   00 94 C8 F2 CF 07 DF 63  .GvI...........c
0100: 77 E1 68 9A F0 14 60 C7   D5 E0 D8 54 5F 8E 14 55  w.h...`....T_..U
0110: 4E 3E BA 11 8D C7 BC C1   E3 57 46 AF AB 38 E4 C6  N>.......WF..8..
0120: 45 31 B4 5C A1 E8 6C 63   DD C3 83 3D D4 96 63 A6  E1.\..lc...=..c.
0130: 65 5C AF 52 5E 6A 9E 81   F8 47 59 56 9C 75 6B 8C  e\.R^j...GYV.uk.
0140: 13 3E 86 3C 62 1A F1 21   2E 4B 38 DE B1 9A CB 83  .>.<b..!.K8.....
0150: BF B5 2B 34 B9 04 E3 64   94 26 F2 55 D3 FF 92 3B  ..+4...d.&.U...;
0160: CA BB 93 9D F3 3E B4                               .....>.

Client Principal = platuser/10.2.177.208@OTOCYON.COM
Server Principal = krbtgt/OTOCYON.COM@OTOCYON.COM
Session Key = EncryptionKey: keyType=18 keyBytes (hex dump)=
0000: E8 8D 26 1C 4B EE 88 CB   77 DE 5F FF 22 10 CD 20  ..&.K...w._."..
0010: 9D BE 4E 74 BC 4E 40 23   20 47 3D 26 D1 ED 00 BE  ..Nt.N@# G=&....


Forwardable Ticket true
Forwarded Ticket false
Proxiable Ticket false
Proxy Ticket false
Postdated Ticket false
Renewable Ticket true
Initial Ticket true
Auth Time = Mon Oct 24 16:37:24 CST 2016
Start Time = Mon Oct 24 16:37:24 CST 2016
End Time = Tue Oct 25 16:37:24 CST 2016
Renew Till = Thu Oct 27 16:37:24 CST 2016
Client Addresses  Null
16/10/25 11:35:00 DEBUG UserGroupInformation: Current time is 1477366500869
16/10/25 11:35:00 DEBUG UserGroupInformation: Next refresh is 1477367364000
16/10/25 11:35:00 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SecurityManager: SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
16/10/25 11:35:01 DEBUG SecurityManager: SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
16/10/25 11:35:01 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
16/10/25 11:35:01 DEBUG PlatformDependent0: java.nio.Buffer.address: available
16/10/25 11:35:01 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
16/10/25 11:35:01 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
16/10/25 11:35:01 DEBUG PlatformDependent0: java.nio.Bits.unaligned: true
16/10/25 11:35:01 DEBUG PlatformDependent: Java version: 7
16/10/25 11:35:01 DEBUG PlatformDependent: -Dio.netty.noUnsafe: false
16/10/25 11:35:01 DEBUG PlatformDependent: sun.misc.Unsafe: available
16/10/25 11:35:01 DEBUG PlatformDependent: -Dio.netty.noJavassist: false
16/10/25 11:35:01 DEBUG PlatformDependent: Javassist: unavailable
16/10/25 11:35:01 DEBUG PlatformDependent: You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
16/10/25 11:35:01 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
16/10/25 11:35:01 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
16/10/25 11:35:01 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
16/10/25 11:35:01 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
16/10/25 11:35:01 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
16/10/25 11:35:01 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
16/10/25 11:35:01 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
16/10/25 11:35:01 DEBUG TransportClientFactory: Creating new connection to /10.2.177.211:40030
16/10/25 11:35:01 DEBUG ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0x62fef1adccf115fd (took 0 ms)
16/10/25 11:35:01 DEBUG ByteBufUtil: -Dio.netty.allocator.type: unpooled
16/10/25 11:35:01 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
16/10/25 11:35:01 DEBUG ResourceLeakDetector: -Dio.netty.leakDetectionLevel: simple
16/10/25 11:35:01 DEBUG TransportClientFactory: Connection to /10.2.177.211:40030 successful, running bootstraps...
16/10/25 11:35:01 DEBUG TransportClientFactory: Successfully created connection to /10.2.177.211:40030 after 104 ms (0 ms spent in bootstraps)
16/10/25 11:35:01 DEBUG Recycler: -Dio.netty.recycler.maxCapacity.default: 262144
16/10/25 11:35:01 INFO SecurityManager: Changing view acls to: platuser
16/10/25 11:35:01 INFO SecurityManager: Changing modify acls to: platuser
16/10/25 11:35:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(platuser); users with modify permissions: Set(platuser)
16/10/25 11:35:01 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SSLOptions: No SSL protocol specified
16/10/25 11:35:01 DEBUG SecurityManager: SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
16/10/25 11:35:01 DEBUG SecurityManager: SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
16/10/25 11:35:01 DEBUG AkkaUtils: In createActorSystem, requireCookie is: off
16/10/25 11:35:02 INFO Slf4jLogger: Slf4jLogger started
16/10/25 11:35:02 INFO Remoting: Starting remoting
16/10/25 11:35:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@10.2.177.211:53622]
16/10/25 11:35:02 INFO Utils: Successfully started service 'sparkExecutorActorSystem' on port 53622.
16/10/25 11:35:02 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
16/10/25 11:35:02 DEBUG TransportClientFactory: Creating new connection to /10.2.177.211:40030
16/10/25 11:35:02 DEBUG TransportClientFactory: Connection to /10.2.177.211:40030 successful, running bootstraps...
16/10/25 11:35:02 DEBUG TransportClientFactory: Successfully created connection to /10.2.177.211:40030 after 3 ms (0 ms spent in bootstraps)
16/10/25 11:35:02 INFO DiskBlockManager: Created local directory at /data_b/spark/spark-3550850d-4fe3-4f11-98d3-815e107272b0/executor-2bc32288-a7d7-41cb-b61d-8c4c3f7c6549/blockmgr-b185c401-5263-4af7-9754-5e56411f9ec4
16/10/25 11:35:02 INFO MemoryStore: MemoryStore started with capacity 511.5 MB
16/10/25 11:35:02 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.2.177.211:40030
16/10/25 11:35:02 INFO WorkerWatcher: Connecting to worker spark://Worker@10.2.177.211:7078
16/10/25 11:35:02 DEBUG TransportClientFactory: Creating new connection to /10.2.177.211:7078
16/10/25 11:35:02 DEBUG TransportClientFactory: Connection to /10.2.177.211:7078 successful, running bootstraps...
16/10/25 11:35:02 DEBUG TransportClientFactory: Successfully created connection to /10.2.177.211:7078 after 24 ms (0 ms spent in bootstraps)
16/10/25 11:35:02 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
16/10/25 11:35:02 INFO Executor: Starting executor ID 0 on host spark177211
16/10/25 11:35:02 DEBUG NetUtil: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%1)
16/10/25 11:35:02 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
16/10/25 11:35:02 DEBUG TransportServer: Shuffle server started on port :58838
16/10/25 11:35:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58838.
16/10/25 11:35:02 INFO NettyBlockTransferService: Server created on 58838
16/10/25 11:35:02 INFO BlockManagerMaster: Trying to register BlockManager
16/10/25 11:35:02 INFO BlockManagerMaster: Registered BlockManager
16/10/25 11:35:02 INFO CoarseGrainedExecutorBackend: Got assigned task 0
16/10/25 11:35:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/10/25 11:35:02 INFO Executor: Fetching http://10.2.177.211:53704/files/spark.token with timestamp 1477366498609
16/10/25 11:35:03 DEBUG Utils: fetchFile not using security
16/10/25 11:35:03 INFO Utils: Fetching http://10.2.177.211:53704/files/spark.token to /data_b/spark/spark-3550850d-4fe3-4f11-98d3-815e107272b0/executor-2bc32288-a7d7-41cb-b61d-8c4c3f7c6549/spark-c6a5de5c-84cd-436a-bc72-862757b601a3/fetchFileTemp6459837870487746741.tmp
16/10/25 11:35:03 INFO Utils: Copying /data_b/spark/spark-3550850d-4fe3-4f11-98d3-815e107272b0/executor-2bc32288-a7d7-41cb-b61d-8c4c3f7c6549/spark-c6a5de5c-84cd-436a-bc72-862757b601a3/7871661121477366498609_cache to /var/run/spark/work/app-20161025113459-0000/0/./spark.token
16/10/25 11:35:03 INFO Executor: Fetching http://10.2.177.211:53704/jars/spark-examples-1.6.2-hadoop2.4.1.jar with timestamp 1477366498816
16/10/25 11:35:03 DEBUG Utils: fetchFile not using security
16/10/25 11:35:03 INFO Utils: Fetching http://10.2.177.211:53704/jars/spark-examples-1.6.2-hadoop2.4.1.jar to /data_b/spark/spark-3550850d-4fe3-4f11-98d3-815e107272b0/executor-2bc32288-a7d7-41cb-b61d-8c4c3f7c6549/spark-c6a5de5c-84cd-436a-bc72-862757b601a3/fetchFileTemp386923766771207292.tmp
16/10/25 11:35:03 INFO Utils: Copying /data_b/spark/spark-3550850d-4fe3-4f11-98d3-815e107272b0/executor-2bc32288-a7d7-41cb-b61d-8c4c3f7c6549/spark-c6a5de5c-84cd-436a-bc72-862757b601a3/18251068861477366498816_cache to /var/run/spark/work/app-20161025113459-0000/0/./spark-examples-1.6.2-hadoop2.4.1.jar
16/10/25 11:35:04 INFO Executor: Adding file:/var/run/spark/work/app-20161025113459-0000/0/./spark-examples-1.6.2-hadoop2.4.1.jar to class loader
16/10/25 11:35:04 DEBUG Executor: Task 0's epoch is 0
16/10/25 11:35:04 DEBUG Executor: ==userName==platuser==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==userName==platuser==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==source==/var/run/spark/work/app-20161025113459-0000/0/./spark.token==
16/10/25 11:35:04 DEBUG : address: spark177211/10.2.177.211 isLoopbackAddress: false, with host 10.2.177.211 spark177211
16/10/25 11:35:04 DEBUG NativeLibraryLoader: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
16/10/25 11:35:04 DEBUG NativeLibraryLoader: -Dio.netty.netty.workdir: /tmp (io.netty.tmpdir)
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==iter==java.util.HashMap$ValueIterator@3ddb547d==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==iter==java.util.HashMap$ValueIterator@3ddb547d==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==ugi==platuser (auth:KERBEROS)==
16/10/25 11:35:04 DEBUG UserGroupInformation: PrivilegedAction as:platuser (auth:KERBEROS) from:org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:251)
16/10/25 11:35:04 DEBUG BlockManager: Getting local block broadcast_0
16/10/25 11:35:04 DEBUG BlockManager: Block broadcast_0 not registered locally
16/10/25 11:35:04 INFO TorrentBroadcast: Started reading broadcast variable 0
16/10/25 11:35:04 DEBUG TorrentBroadcast: Reading piece broadcast_0_piece0 of broadcast_0
16/10/25 11:35:04 DEBUG BlockManager: Getting local block broadcast_0_piece0 as bytes
16/10/25 11:35:04 DEBUG BlockManager: Block broadcast_0_piece0 not registered locally
16/10/25 11:35:04 DEBUG BlockManager: Getting remote block broadcast_0_piece0 as bytes
16/10/25 11:35:04 DEBUG BlockManager: Getting remote block broadcast_0_piece0 from BlockManagerId(driver, 10.2.177.211, 58603)
16/10/25 11:35:04 DEBUG TransportClientFactory: Creating new connection to /10.2.177.211:58603
16/10/25 11:35:04 DEBUG TransportClientFactory: Connection to /10.2.177.211:58603 successful, running bootstraps...
16/10/25 11:35:04 DEBUG TransportClientFactory: Successfully created connection to /10.2.177.211:58603 after 3 ms (0 ms spent in bootstraps)
16/10/25 11:35:04 DEBUG TransportClient: Sending fetch chunk request 0 to /10.2.177.211:58603
16/10/25 11:35:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1218.0 B, free 1218.0 B)
16/10/25 11:35:04 DEBUG BlockManagerMaster: Updated info of block broadcast_0_piece0
16/10/25 11:35:04 DEBUG BlockManager: Told master about block broadcast_0_piece0
16/10/25 11:35:04 DEBUG BlockManager: Put block broadcast_0_piece0 locally took  29 ms
16/10/25 11:35:04 DEBUG BlockManager: Putting block broadcast_0_piece0 without replication took  30 ms
16/10/25 11:35:04 INFO TorrentBroadcast: Reading broadcast variable 0 took 131 ms
16/10/25 11:35:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1904.0 B, free 3.0 KB)
16/10/25 11:35:04 DEBUG BlockManager: Put block broadcast_0 locally took  108 ms
16/10/25 11:35:04 DEBUG BlockManager: Putting block broadcast_0 without replication took  109 ms
16/10/25 11:35:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1033 bytes result sent to driver
16/10/25 11:35:04 INFO CoarseGrainedExecutorBackend: Got assigned task 1
16/10/25 11:35:04 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/10/25 11:35:04 DEBUG Executor: Task 1's epoch is 0
16/10/25 11:35:04 DEBUG Executor: ==userName==platuser==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==userName==platuser==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==source==/var/run/spark/work/app-20161025113459-0000/0/./spark.token==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==iter==java.util.HashMap$ValueIterator@7f2c5728==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==iter==java.util.HashMap$ValueIterator@7f2c5728==
16/10/25 11:35:04 DEBUG SparkHadoopUtil: ==ugi==platuser (auth:KERBEROS)==
16/10/25 11:35:04 DEBUG UserGroupInformation: PrivilegedAction as:platuser (auth:KERBEROS) from:org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:251)
16/10/25 11:35:04 DEBUG BlockManager: Getting local block broadcast_0
16/10/25 11:35:04 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)
16/10/25 11:35:04 DEBUG BlockManager: Getting block broadcast_0 from memory
16/10/25 11:35:04 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1033 bytes result sent to driver
16/10/25 11:35:05 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
16/10/25 11:35:05 INFO MemoryStore: MemoryStore cleared
16/10/25 11:35:05 INFO BlockManager: BlockManager stopped
16/10/25 11:35:05 INFO RemoteActorRefProvider$RemotingTerm